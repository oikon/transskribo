# Transskribo — Progress Log
#
# Format:
#   Each entry is a block with the following fields:
#
#   ## YYYY-MM-DD HH:MM — Session N: <title>
#   Features: <comma-separated requirement IDs completed>
#   Status: success | partial | failed
#   Notes:
#     - <what was done>
#     - <what was done>
#   Issues:
#     - <any problems encountered, or "none">
#
# This file is updated by each headless session after completing work.
# It serves as a handoff log between sessions.

## 2026-02-12 — Session 1: Project Skeleton & Configuration
Features: 1.01, 1.02, 1.03, 2.01, 2.02, 2.03, 2.04, 2.05
Status: success
Notes:
  - Created pyproject.toml with all dependencies and entry point
  - Created src/transskribo/__init__.py with __version__
  - Created src/transskribo/cli.py with Typer app and placeholder run command
  - Created .gitignore for Python project
  - Created config.example.toml with all documented options
  - Created tests/conftest.py with shared fixtures (tmp dirs, sample config)
  - Implemented TransskriboConfig frozen dataclass with all fields and defaults
  - Implemented load_config() for TOML parsing
  - Implemented merge_config() with defaults < file < CLI override priority
  - Implemented config validation (input_dir exists, output_dir creatable, hf_token required)
  - HF_TOKEN env var fallback works correctly
  - Wrote 20 tests covering all config functionality
  - All tests pass, ruff clean, pyright clean
Issues:
  - none

## 2026-02-12 — Session 2: Logging, File Scanner & Validation
Features: 3.01, 3.02, 4.01, 4.02, 4.03, 5.01, 5.02, 5.03
Status: success
Notes:
  - Implemented setup_logging() in logging_setup.py with rich stdout + rotating file handler
  - Wrote 6 tests for logging (handler attachment, file creation, message routing, level filtering)
  - Implemented AudioFile frozen dataclass and scan_directory() in scanner.py
  - Supports 14 extensions (8 audio + 6 video), case-insensitive, with mirrored output paths
  - Implemented filter_already_processed() to skip files with existing output
  - Wrote 13 tests for scanner (empty dir, nested dirs, extensions, filtering, frozen dataclass)
  - Implemented ValidationResult frozen dataclass and check_ffprobe_available() in validator.py
  - Implemented validate_file() using ffprobe subprocess with all rejection checks
  - Wrote 14 tests for validator (zero-length, valid audio, video+audio, no audio, corrupt, max duration, timeout, invalid JSON, no duration)
  - All 53 tests pass, ruff clean, pyright clean
Issues:
  - none

## 2026-02-12 — Session 3: Hashing & Registry
Features: 6.01, 6.02, 6.03, 6.04
Status: success
Notes:
  - Implemented compute_hash() with streaming SHA-256 in hasher.py
  - Defined RegistryEntry frozen dataclass with all fields (source_path, output_path, timestamp, status, duration_audio_secs, timing, error)
  - Implemented load_registry() and save_registry() with atomic write (tempfile + rename)
  - Implemented lookup_hash() that returns entry only for status "success"
  - Implemented register_hash() that creates RegistryEntry and stores as dict
  - Wrote 22 tests covering hash determinism, registry CRUD, atomic write safety, lookup hit/miss/failed-status, register with timing data, full roundtrip
  - All 75 tests pass, ruff clean, pyright clean
Issues:
  - none

## 2026-02-12 — Session 4: Transcriber (WhisperX Wrapper)
Features: 7.01, 7.02, 7.03, 7.04, 7.05
Status: success
Notes:
  - Implemented load_audio() wrapping whisperx.load_audio() in transcriber.py
  - Implemented load_whisper_model(), transcribe(), align(), unload_whisper_model() for transcription stage
  - align() loads alignment model, runs alignment, then frees alignment model and clears VRAM
  - Implemented load_diarization_pipeline(), diarize(), assign_speakers(), unload_diarization_pipeline() for diarization stage
  - DiarizationPipeline imported from whisperx.diarize (not on top-level whisperx module)
  - Implemented process_file() orchestrator with per-stage timing via time.monotonic()
  - Models loaded/unloaded per stage with finally blocks ensuring VRAM cleanup on errors
  - Audio loaded once via load_audio(), ndarray passed to transcribe+align; pyannote takes audio_path
  - Wrote 15 mock tests covering: individual function args, VRAM cleanup, full lifecycle order, timing collection, error cleanup, models never loaded simultaneously
  - All 90 tests pass, ruff clean, pyright clean
Issues:
  - none

## 2026-02-12 — Session 5: Output Writer & Reporter
Features: 8.01, 8.02, 8.03, 9.01, 9.02, 9.03, 9.04, 9.05
Status: success
Notes:
  - Implemented build_output_document() in output.py structuring JSON with segments, words, metadata
  - Segments contain start, end, text, speaker, and nested words list
  - Words are flattened into a top-level list with start, end, word, score, speaker
  - Metadata includes source_file, file_hash, duration_secs, num_speakers, model_size, language, processed_at, timing
  - num_speakers auto-counted from unique speakers in segments if not provided in metadata
  - Implemented write_output() with atomic write (tempfile + rename) and parent dir creation
  - Implemented copy_duplicate_output() that copies output JSON and updates source_file + processed_at in metadata
  - Wrote 18 tests for output.py covering document structure, empty/missing segments, unicode, atomic write safety, duplicate copy
  - Implemented compute_statistics() in reporter.py reusing scan_directory for total file count
  - Implemented compute_timing_statistics() with per-stage avg/min/max, speed ratio (audio/processing), total count
  - Implemented per_directory_breakdown() grouping stats by top-level subdirectory relative to input_dir
  - Implemented format_report() rendering rich tables for progress, timing, and per-directory sections with ETA
  - Wrote 27 tests for reporter.py covering statistics computation, timing stats, breakdown grouping, report formatting
  - All 135 tests pass, ruff clean, pyright clean
Issues:
  - none

## 2026-02-12 — Session 6: CLI Integration & Pipeline Wiring
Features: 10.01, 10.02, 10.03, 10.04, 10.05, 10.06
Status: success
Notes:
  - Rewrote cli.py with full run command: CLI args (--config, --input-dir, --output-dir, --model-size, --batch-size), config loading, logging setup, ffprobe fail-fast check
  - Wired pipeline skeleton: scan_directory → filter_already_processed → validate_file per file, storing duration_secs for registry
  - Added rich progress bar with file count, current file name, and elapsed time
  - Wired hash-based duplicate detection: compute_hash → lookup_hash → copy_duplicate_output or transcribe
  - Wired transcription: process_file → build_output_document → write_output → register_hash with timing + duration_audio_secs
  - Per-file errors caught, logged, registered as "failed" in registry, batch continues
  - Batch summary logged at end: processed, failed, skipped, invalid, duplicates, total time
  - Implemented report command: loads config+registry, computes stats+timing+breakdown, prints rich formatted report
  - Implemented version command: prints transskribo version
  - Transcriber imported lazily inside _process_single_file to avoid loading torch/whisperx at CLI startup
  - Wrote 16 tests covering CLI arg parsing, ffprobe check, config overrides, pipeline flow, invalid file skipping, duplicate handling, successful processing, error handling, batch summary, report command, version command, helper functions
  - All 151 tests pass, ruff clean, pyright clean
Issues:
  - none

## 2026-02-12 — Session 7: Polish & Hardening
Features: 11.01, 11.02, 11.03, 11.04
Status: success
Notes:
  - Added --retry-failed flag to run command: loads failed entries from registry, re-includes files with status "failed" in the processing loop even if output exists
  - Added --dry-run flag to run command: scans, validates, and logs what would be processed without running transcription or writing outputs
  - Implemented graceful SIGINT/SIGTERM handling: signal handler sets _shutdown_requested flag, pipeline loop checks before each file, finishes current file, saves registry, logs partial batch summary
  - Signal handlers are installed in _run_pipeline and restored in a finally block
  - Refactored _run_pipeline into _run_pipeline (signal setup/teardown) and _run_pipeline_inner (logic) for clean separation
  - Added _get_failed_hashes() helper to extract failed source paths from registry
  - Wrote 14 new tests: retry-failed reprocessing, retry with no failures, skip without retry flag, dry-run no processing, dry-run logs summary, dry-run still validates, SIGINT stops after current file, signal flag test, shutdown saves registry, full pipeline end-to-end, error+retry flow, dry-run→real-run sequence, _get_failed_hashes unit tests
  - All 165 tests pass, ruff clean, pyright clean
Issues:
  - none

## 2026-02-12 — Session 8: Batch Limit Controls
Features: 12.01, 12.02, 12.03, 12.04
Status: success
Notes:
  - Added --max-files CLI option to run command (int, default 0 = no limit)
  - Added --max-processing-minutes CLI option to run command (float, default 0 = no limit)
  - --max-files counts only successful transcriptions; duplicates, errors, invalid files do not count
  - --max-processing-minutes checks wall-clock elapsed time before each file; current file always finishes
  - Both limits passed through run → _run_pipeline → _run_pipeline_inner
  - Limit checks sit alongside existing _shutdown_requested flag at top of file loop
  - Batch summary shows "Partial Batch Summary (interrupted)" and stop reason when a limit is hit
  - Wrote 15 new tests: max-files stops after N, max-files ignores duplicates, max-files ignores errors, max-files 0 = no limit, max-files logs stop reason, max-processing-minutes stops after elapsed time (time.monotonic mocked via state-based approach to handle Rich Progress internal calls), max-processing-minutes 0 = no limit, max-processing-minutes logs stop reason, dry-run ignores max-files, SIGINT takes priority over max-files
  - All 180 tests pass, ruff clean, pyright clean
Issues:
  - none

## 2026-02-12 — Session 9: Enrichment & Document Generation
Features: 13.01, 13.02, 13.03, 13.04, 13.05, 13.06, 13.07, 13.08, 13.09, 13.10, 13.11
Status: success
Notes:
  - Added openai and docxtpl dependencies to pyproject.toml
  - Defined EnrichConfig frozen dataclass with fields: llm_base_url, llm_api_key, llm_model, template_path, transcritor
  - Implemented load_enrich_config() reading [enrich] TOML section with defaults/file/CLI/env var merge
  - Updated config.example.toml with [enrich] section and comments
  - Created enricher.py with extract_text, group_speaker_turns, is_enriched, call_llm (OpenAI SDK), enrich_document
  - Created docx_writer.py with generate_docx using docxtpl template rendering
  - Added enrich CLI command: batch mode (all JSONs in output_dir), single-file mode (--file), --force flag
  - Batch mode: discovers result JSONs, skips .transskribo/ dir, skips non-transskribo JSONs, skips already-enriched (unless --force), per-file error handling continues batch, generates .docx alongside each .json
  - Updated compute_statistics() in reporter.py with enriched/not_enriched counts from output_dir scan
  - Updated format_report() to display enrichment progress row (e.g., "Enriched: 42 / 100")
  - Wrote 11 tests for EnrichConfig (defaults, TOML loading, env var fallback, CLI overrides, frozen)
  - Wrote 18 tests for enricher.py (extract_text, group_speaker_turns, is_enriched, call_llm mock, enrich_document)
  - Wrote 4 tests for docx_writer.py (create file, template not found, context vars, parent dirs)
  - Wrote 12 tests for enrich CLI command (batch, single-file, skip, force, errors, docx, transskribo dir)
  - Wrote 8 tests for enrichment reporter stats (enriched/not enriched counts, mixed states, skip logic)
  - All 233 tests pass, ruff clean, pyright clean
Issues:
  - none

## 2026-02-13 — Session 10: Export Command & Config Refactor
Features: 14.01, 14.02, 14.03, 14.04, 14.05, 14.06
Status: success
Notes:
  - Removed template_path and transcritor from EnrichConfig
  - Defined ExportConfig frozen dataclass with template_path and transcritor fields
  - Implemented load_export_config() reading [export] TOML section with defaults/file/CLI merge
  - Added _EXPORT_DEFAULTS dict, updated config.example.toml with separate [enrich] and [export] sections
  - Updated docx_writer.py: generate_docx now accepts ExportConfig instead of EnrichConfig
  - Refactored enrich command: removed all docx generation logic from _enrich_single_file and _enrich_batch
  - Enrich command now only does: read JSON → check is_enriched → call enrich_document → write updated JSON
  - Implemented export command with --config, --file, --force, --docx options
  - Export requires at least one format flag (--docx), exits with error if none provided
  - Batch mode: discovers enriched JSONs, skips non-enriched with warning, skips already-exported unless --force
  - Single-file mode: exports one file with same skip logic
  - Updated reporter.py: _count_enrichment_and_exports counts .docx files alongside enriched JSONs
  - format_report now shows full pipeline progress: Transcribed X/total, Enriched X/transcribed, Exported (docx) X/enriched
  - Updated test_config.py: added 7 ExportConfig tests, updated EnrichConfig tests to remove template_path/transcritor
  - Updated test_docx_writer.py: uses ExportConfig instead of EnrichConfig
  - Updated test_enrich_cli.py: removed docx assertions, added test_batch_does_not_generate_docx
  - Wrote tests/test_export_cli.py with 14 tests (batch, single-file, force, skip, errors, formats, edge cases)
  - Updated test_reporter.py: added 6 tests for export stats and pipeline progress display
  - All 267 tests pass, ruff clean, pyright clean
Issues:
  - none
